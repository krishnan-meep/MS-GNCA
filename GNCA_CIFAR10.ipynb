{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import torchode as to\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from pytorch_msssim import SSIM, MS_SSIM, ssim\n",
    "from focal_frequency_loss import FocalFrequencyLoss as FFL\n",
    "\n",
    "from IPython.display import Image, Video, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True\n",
    "    ,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "data, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(data[:10], nrow=5, padding=0).permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNCA(nn.Module):\n",
    "    def __init__(self, latent_dim, aug_dim, img_dim=(32, 32)):\n",
    "        super(GNCA, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.aug_dim = aug_dim\n",
    "        self.h, self.w = img_dim[0], img_dim[1]\n",
    "        self.set_modules()\n",
    "        \n",
    "    def set_modules(self):\n",
    "        sobel_x = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        sobel_y = torch.Tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "        laplace = torch.Tensor([[1, 2, 1], [2, -12, 2], [1, 2, 1]])\n",
    "\n",
    "        self.C_S_x = nn.Conv2d(self.aug_dim, self.aug_dim, kernel_size = 3, stride = 1, padding = 1, bias = False, groups = self.aug_dim)\n",
    "        self.C_S_x.weight = nn.Parameter(sobel_x.unsqueeze(0).repeat(self.aug_dim, 1, 1, 1), requires_grad = False)\n",
    "\n",
    "        self.C_S_y = nn.Conv2d(self.aug_dim, self.aug_dim, kernel_size = 3, stride = 1, padding = 1, bias = False, groups = self.aug_dim)\n",
    "        self.C_S_y.weight = nn.Parameter(sobel_y.unsqueeze(0).repeat(self.aug_dim, 1, 1, 1), requires_grad = False)\n",
    "        \n",
    "        self.C_S_l = nn.Conv2d(self.aug_dim, self.aug_dim, kernel_size = 3, stride = 1, padding = 1, bias = False, groups = self.aug_dim)\n",
    "        self.C_S_l.weight = nn.Parameter(laplace.unsqueeze(0).repeat(self.aug_dim, 1, 1, 1), requires_grad = False)\n",
    "\n",
    "        self.PosEmb = nn.Parameter(torch.randn(1, self.aug_dim, 32, 32), requires_grad=True)\n",
    "        self.G0, self.B0 = nn.Linear(self.latent_dim, self.aug_dim), nn.Linear(self.latent_dim, self.aug_dim)\n",
    "\n",
    "        self.D1 = nn.Conv2d(6*self.aug_dim + self.latent_dim, 128, 1, 1, 0)\n",
    "        #self.D2 = nn.Conv2d(64, 64, 1, 1, 0)\n",
    "        #self.D3 = nn.Conv2d(64, 64, 1, 1, 0)\n",
    "        self.D4 = nn.Conv2d(128, self.aug_dim, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.Pool = nn.MaxPool2d(3, stride = 1, padding = 1)\n",
    "        self.scale = nn.Parameter(torch.ones(1, self.aug_dim, 32, 32), requires_grad=True)\n",
    "\n",
    "    def perceive(self, x):\n",
    "        #g, b = self.G0(z)[:, :, None, None], self.B0(z)[:, :, None, None]\n",
    "        #x = g*x + b\n",
    "        x1 = self.C_S_x(x)    #SobelX\n",
    "        x2 = self.C_S_y(x)    #Sobel Y\n",
    "        x3 = self.C_S_l(x)    #Sobel Y            #Identity\n",
    "        x = torch.cat([x1, x2, x3, x, self.Pool(x), -self.Pool(-x)], dim = 1)\n",
    "        return x\n",
    "\n",
    "    def update(self, x, z):\n",
    "        x = torch.cat([x, z[:, :, None, None].repeat(1, 1, self.h, self.w)], dim=1)\n",
    "        x = self.D1(x)\n",
    "        x = F.elu(x)\n",
    "        #x = F.elu(self.D2(x))\n",
    "        #x = F.elu(self.D3(x))\n",
    "        return self.D4(x)\n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        x_i = x.clone()\n",
    "        #x = x + self.PosEmb\n",
    "        x = self.perceive(x)\n",
    "        x = self.update(x, z)\n",
    "        x = x_i + x\n",
    "        x = F.dropout(x, p=0.01)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Encoda(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoda, self).__init__()\n",
    "\n",
    "        self.N = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "        )\n",
    "        self.F = nn.Linear(2*2*64, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.N(x).reshape(x.shape[0], -1)\n",
    "        return torch.tanh(self.F(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "ts = torch.linspace(0, 1, 16).to(device)\n",
    "aug_dim = 16\n",
    "latent_dim = 128\n",
    "\n",
    "netEnc = Encoda(latent_dim).to(device)\n",
    "netG = GNCA(latent_dim, aug_dim).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ffl = FFL(loss_weight=1.0, alpha=1.0) \n",
    "#optG = optim.SGD(netG.parameters(), 0.01)\n",
    "#optG = optim.Adam(netG.parameters(), lr=1e-3)\n",
    "optG = AdaBelief(netG.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False)\n",
    "optEnc = AdaBelief(netEnc.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False)\n",
    "\n",
    "def lossfn(x, y):\n",
    "    #loss = 1 - ssim(x, y, data_range=1, size_average=True)\n",
    "    loss = ((x - y)**2).mean()\n",
    "    #loss += ffl(x, y)\n",
    "    return loss\n",
    "\n",
    "#images, _ = next(iter(trainloader)) \n",
    "\n",
    "for step in range(0, 10000):\n",
    "    start = time.time()\n",
    "    \n",
    "    images, _ = next(iter(trainloader)) \n",
    "    images = images.to(device)\n",
    "    b_size = images.shape[0]\n",
    "    \n",
    "    seed = torch.zeros(b_size, aug_dim, 32, 32).to(device)\n",
    "\n",
    "    optEnc.zero_grad()\n",
    "    optG.zero_grad()\n",
    "    \n",
    "    z = netEnc(images)\n",
    "    \n",
    "    g = seed.clone()\n",
    "    g[:, :3, 0, 0] = 1\n",
    "\n",
    "    outs = []\n",
    "    out = g\n",
    "    for i in range(32):\n",
    "        out = netG(out, z)\n",
    "        outs.append(out.unsqueeze(0))\n",
    "    outs = torch.cat(outs)\n",
    "\n",
    "    L = 0\n",
    "    for i in range(1, 32):\n",
    "        L += lossfn(outs[i][:, :3, :i, :i], images[:, :, :i, :i])\n",
    "    \n",
    "    L.backward()\n",
    "    optG.step()\n",
    "    optEnc.step()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if step%20 == 0:\n",
    "        print(f\"Step: {step} Loss: {L.item()} (Gen) Time per step: {round(end - start, 3)}s\")\n",
    "        #print(z.mean(), z.std()\n",
    "    if step%100 == 0:\n",
    "        print(f\"Images, reconstruction\")\n",
    "\n",
    "        train_imgs = torch.cat([images[:8], outs[-1][:8, :3]], dim=0)\n",
    "        grid = torchvision.utils.make_grid(train_imgs, nrow=8, padding=0).permute(1, 2, 0).cpu().detach().numpy()\n",
    "        plt.imshow(grid)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
